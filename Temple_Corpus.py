import shutil
import requests
from bs4 import BeautifulSoup
import re
import os
import urllib3
from PIL import Image
import io
import time

from location_details_api import get_location_details
from urllib.error import URLError
from urllib.robotparser import RobotFileParser
from urllib.parse import unquote
from urllib.parse import urlparse
from datetime import datetime

import mysql.connector
from geopy.geocoders import Nominatim

db_config = {
    'host': 'localhost',
    'user': 'root',
    'password': '',
    'database': 'temple_corpus'
}

# Connection and cursor settings
connection = mysql.connector.connect(**db_config)

cursor = connection.cursor()
# end of connection settings

my_list_web = []
my_list = []
list_p = []
# List of URLs to skip
skip_site = "www.tripadvisor.in"


# ________________________________________________________________________________________________________________________________
# Insertion code for the db connection

# Check for phone number
def update_temple_phone(temple_name, phone_official_site):
    # Phone Regex
    phone_number_pattern = r'^\d{4}\s\d{3}\s\d{4}$|^\d{11}$'
    check_placeholder_sql = "SELECT phone_official_site FROM temples WHERE temple_name = %s"
    cursor.execute(check_placeholder_sql, (temple_name,))
    existing_phone = cursor.fetchone()[0]
    existing_phone = existing_phone.strip()

    if existing_phone in ["Empty Phone", "Phone number not available ,International phone number not available", ""]:
        if existing_phone != phone_official_site:
            # Update phone number
            update_phone_sql = "UPDATE temples SET phone_official_site = %s WHERE temple_name = %s"
            cursor.execute(update_phone_sql, (phone_official_site, temple_name))
            connection.commit()
            print(f"Success: Phone number updated for {temple_name}.")

    elif existing_phone and re.match(phone_number_pattern, existing_phone):
        if existing_phone != phone_official_site:
            # Update the database with the new combined numbers
            update_phone_sql = "UPDATE temples SET phone_official_site = %s WHERE temple_name = %s"
            cursor.execute(update_phone_sql, (phone_official_site, temple_name))
            connection.commit()
            print(f"Success: Phone number updated for {temple_name}.")
    # else:
    #     print(f"Skipping update for Phone {temple_name}.")


# Insertion Descriptions to temple_descriptions table
def add_temple_description(temple_name, description, websites):
    if description == "An appropriate representation of the requested resource could not be found on this server. This error was generated by Mod_Security.":
        print("Warning: Mod_Security not updating the description ")
        return False
    cursor = connection.cursor(buffered=True)
    fetch_temple_id_sql = "SELECT temple_id FROM temples WHERE temple_name = %s"
    cursor.execute(fetch_temple_id_sql, (temple_name,))
    temple_id = cursor.fetchone()

    if temple_id:
        temple_id = temple_id[0]  # Extracting the temple_id value

        # Fetch existing website
        fetch_existing_websites_sql = "SELECT websites FROM temple_descriptions WHERE temple_id = %s"
        cursor.execute(fetch_existing_websites_sql, (temple_id,))
        existing_websites = cursor.fetchall()

        # Fetch from temples table
        fetch_website_sql = "SELECT websites FROM temples WHERE temple_name = %s"
        cursor.execute(fetch_website_sql, (temple_name,))
        result = cursor.fetchone()
        existing_websites.append(result)

        fetch_desc_sql = "SELECT description FROM temples WHERE temple_name = %s"
        cursor.execute(fetch_desc_sql, (temple_name,))
        cursor.execute(fetch_desc_sql, (temple_name,))
        existing_desc = cursor.fetchone()
        existing_desc = existing_desc[0]

        # Flatten list of tuples into list of strings
        existing_websites = [website[0] for website in existing_websites]

        # Check if new website is in existing websites
        if websites not in existing_websites:
            # Inserting or updating temple description with fetched temple_id, description, and new_website
            insert_or_update_desc_sql = """
            INSERT INTO temple_descriptions (temple_id, description, websites) 
            VALUES (%s, %s, %s)
            ON DUPLICATE KEY UPDATE 
            description = VALUES(description), 
            websites = VALUES(websites)
            """
            desc_values = (temple_id, description, websites)
            cursor.execute(insert_or_update_desc_sql, desc_values)
            connection.commit()
            if existing_desc == " " or existing_desc == "":
                insert_or_update_desc_sql = """
                    UPDATE temples
                    SET description = %s
                    WHERE temple_name = %s
                    """
                desc_values = (description, temple_name)
                cursor.execute(insert_or_update_desc_sql, desc_values)
                connection.commit()
            print("Success: Inserted or Updated Description and Website URL")
        # else:
        #     print("Website URL is already in the database. No update needed.")


# Update Address
def update_temple_address(temple_name, new_location):
    # Fetch existing address
    fetch_existing_address_sql = "SELECT location FROM temples WHERE temple_name = %s"
    cursor.execute(fetch_existing_address_sql, (temple_name,))
    existing_location = cursor.fetchone()

    # Check if new address is longer than existing address
    if existing_location and len(new_location) > len(existing_location[0]):
        # Update address
        update_address_sql = """
        UPDATE temples
        SET location = %s
        WHERE temple_name = %s
        """
        cursor.execute(update_address_sql, (new_location, temple_name))
        connection.commit()
        print("Success: Updated Address")
    # else:
    #     print("Address is already in the database. No update needed.")


def update_temple_email(temple_name, new_email):
    # Fetch existing email
    fetch_existing_email_sql = "SELECT email_official_site FROM temples WHERE temple_name = %s"
    cursor.execute(fetch_existing_email_sql, (temple_name,))
    existing_email = cursor.fetchone()

    # Check if new email is not empty and different from existing email
    if existing_email and new_email and new_email != existing_email[0] and new_email != "Email not available":
        # Update email
        update_email_sql = """
        UPDATE temples
        SET email_official_site = %s
        WHERE temple_name = %s
        """
        cursor.execute(update_email_sql, (new_email, temple_name))
        connection.commit()
        print("Success: Updated Email")
    # else:
    #     print("Email is already in the database. No update needed.")


def update_image_path(temple_name, new_image_path):
    # Fetch existing email
    fetch_existing_image_sql = "SELECT image_path FROM temples WHERE temple_name = %s"
    cursor.execute(fetch_existing_image_sql, (temple_name,))
    existing_image_path = cursor.fetchone()
    existing_image_path = existing_image_path[0]
    # Check if new email is empty
    if existing_image_path == " " or existing_image_path == "":
        # Update image_path
        update_img_sql = """
        UPDATE temples
        SET image_path = %s
        WHERE temple_name = %s
        """
        cursor.execute(update_img_sql, (new_image_path, temple_name))
        connection.commit()
        print("Success: Updated Images Path")
    # else:
    #     print("Email is already in the database. No update needed.")


def insert_temple_data(temple_name, deity_name, description, image_path, location, latitude, longitude, opening_hours,
                       ways_to_book, websites, phone_official_site, email_official_site):
    # Check if the record already exists
    check_sql = "SELECT COUNT(*) FROM temples WHERE temple_name = %s"
    cursor.execute(check_sql, (temple_name,))
    count = cursor.fetchone()[0]

    if count == 0:
        # Record does not exist, perform the insertion
        sql = """
        INSERT INTO temples (
            temple_name, deity_name, description, image_path, location, latitude, longitude, OpeningHours, ways_to_book, websites, phone_official_site, email_official_site
        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        """
        values = (
            temple_name, deity_name, description, image_path, location, latitude, longitude, opening_hours,
            ways_to_book, websites, phone_official_site, email_official_site
        )
        cursor.execute(sql, values)
        connection.commit()
        print("Success: Inserted Data")

    # Edit by Aman
    # Assuming you've checked for existence as in your previous code
    elif count > 0:
        # For Updating Phone Number
        update_temple_phone(temple_name, phone_official_site)

        # For Add Description to Temple_Descriptions table
        add_temple_description(temple_name, description, websites)

        # For Updating Address
        update_temple_address(temple_name, location)

        # For Updating Email
        update_temple_email(temple_name, email_official_site)

        # For Updating Images_Path
        update_image_path(temple_name, image_path)

    else:
        print(f"Multiple Record for {temple_name} already exists. Skipping insertion.")


def insert_temple_images(temple_name, img_path):
    # Query to get the temple_id from the temples table
    cursor.execute("SELECT temple_id FROM temples WHERE temple_name = %s", (temple_name,))
    result = cursor.fetchone()

    # Extract the temple_id from the tuple
    temple_id = result[0] if result else None
    if temple_id is not None:
        # Query to check if the img_path already exists for the temple_id
        cursor.execute(
            "SELECT 1 FROM temple_images WHERE temple_id = %s AND img_path = %s",
            (temple_id, img_path)
        )
        exists = cursor.fetchone()
        if exists:
            print("Error: img_path already exists for this temple_id")
        else:
            # Query to insert the data into the temple_images table
            cursor.execute(
                "INSERT INTO temple_images (temple_id, img_path, added_on) VALUES (%s, %s, %s)",
                (temple_id, img_path, datetime.now())
            )
            connection.commit()
    else:
        print("Error: Temple_id not found")


def insert_temple_data_by_api(temple_name, location, latitude, longitude, opening_hours, phone_official_site,
                              email_official_site):
    # SQL query to fetch the temple_id
    fetch_temple_id_sql = "SELECT temple_id FROM temples WHERE temple_name = %s"
    cursor.execute(fetch_temple_id_sql, (temple_name,))
    result = cursor.fetchone()

    # Extract the temple_id from the tuple
    temple_id = result[0] if result else None

    # SQL query to update the temple details
    update_sql = """
    UPDATE temples
    SET  location = %s, latitude = %s, longitude = %s, OpeningHours = %s
    WHERE temple_id = %s
    """
    values = (location, latitude, longitude, opening_hours, temple_id)

    # Execute the SQL query
    cursor.execute(update_sql, values)
    connection.commit()

    # For Updating Phone Number
    update_temple_phone(temple_name, phone_official_site)
    # For Updating Email
    update_temple_email(temple_name, email_official_site)
    print("Success :Updated with API")


def fetch_temple_address(temple_name):
    # SQL query to fetch the address
    fetch_address_sql = "SELECT location FROM temples WHERE temple_name = %s"
    cursor.execute(fetch_address_sql, (temple_name,))
    result = cursor.fetchone()
    # Extract the address from the tuple
    address = result[0] if result else None

    return address


# ________________________________________________________________________________________________________________________________

# Formating Phone Number
def format_phone_number(phone_numbers):
    if phone_numbers == "Phone number not available ,International phone number not available":
        return phone_numbers
    numbers = re.findall(r'\+?[\d\s-]+', phone_numbers)  # Find all numbers (with or without + sign) in the string
    formatted_numbers = []

    for number in numbers:
        cleaned_number = re.sub(r'[-\s]', '', number)  # Remove hyphens and spaces

        country_code = re.match(r'^(\+\d+)', cleaned_number)
        if country_code:
            country_code = country_code.group(1)
            cleaned_number = cleaned_number[len(country_code):]
        else:
            country_code = ''

        formatted_number = country_code + cleaned_number
        formatted_numbers.append(formatted_number)

    return ', '.join(formatted_numbers)  # Join the numbers into a single string


def get_absolute_url(src, base_url):
    pattern = r'\b\w+\b/'
    while "../" in src:
        src = src.replace("../", "")
    src = src.lstrip('/')
    # Getting rid of netloc
    parts = src.split('/', 1)
    # print("parts by /: ",parts[0])
    if src.startswith('https://'):
        return src
    elif re.match(r'^\b\w+\b\.', parts[0]):
        src = f"https://{src}"
    else:
        src = f"{base_url}/{src}"
    # putting base
    # print("base_url:--------- ", src)
    return src


def is_valid_url(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'}
    try:
        response = requests.head(url, headers=headers, allow_redirects=True)
        if response.status_code == 200:
            return True
        else:
            return False
    except requests.RequestException:
        return False


def process_images(images, base_url, temple_name):
    list_img = []
    i = 0
    for i, image in enumerate(images):
        src = image.get('src')
        srcset = image.get('srcset')
        if srcset:
            src = srcset.split(',')[-1].split()[0]
        ext = ""
        if src is None:
            continue
        if '.' in src:
            ext = src[src.rindex('.'):]
        file_name = src.split('/')[-1].split('.')[0]
        if src.endswith(('.png', '.jpg', '.jpeg')):
            src = get_absolute_url(src, base_url)

            if not is_valid_url(src):
                print(f"Invalid URL: {src}")
                continue
            # Download the image
            r = requests.get(src, stream=True)

            # Check if the image is less than 2MB
            content_size = int(r.headers.get('content-length', 0))
            img_path = f'images/{temple_name}/{file_name}_{content_size}{ext}'

            # print(f"content: {content_size / 1000}KB, url {src}")
            if 35 * 1024 <= content_size <= 5 * 1024 * 1024:  # 100KB-5MB in bytes
                # Save the image in the images directory
                print("Image URL: ", src)
                with open(img_path, 'wb') as out_file:
                    r.raw.decode_content = True
                    shutil.copyfileobj(r.raw, out_file)
                    list_img.append((img_path, content_size))
            elif content_size >= 5 * 1024 * 1024:
                print("Image URL: ", src)
                img = Image.open(io.BytesIO(r.content))
                img.save(img_path, optimize=True, quality=70)
                list_img.append((img_path, content_size))
            else:
                print("Filtering Images")

    print("images add")
    return list_img


def is_crawling_allowed(url):
    try:
        rp = RobotFileParser()
        robots_url = f"{url.rstrip('/')}/robots.txt"
        rp.set_url(robots_url)
        rp.read()
        return rp.can_fetch("*", url)
    except URLError as e:
        print(f"Error while fetching robots.txt(robots.txt file does not exist for this website)")
        return True


def crawl(url, limit, li, deity_name, address, temple_name):
    flag = 0
    if limit <= 0:
        return
    # parse url for the base url
    parsed = urlparse(url)
    scheme = parsed.scheme
    base_url = parsed.netloc
    base_url = f"{scheme}://{base_url}"

    # Send a GET request to the specified URL
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'}
    # response = requests.get(url, headers=headers, verify=False)

    try:
        response = requests.get(url, headers=headers, verify=False, timeout=5)  # wait for 5 seconds
    except requests.exceptions.Timeout:
        print("Timeout occurred")
        return None
    # Parse the HTML content using BeautifulSoup
    soup = BeautifulSoup(response.content, 'html.parser')
    # Extract relevant information or perform desired actions
    # For example, you could print the page title
    # print("Title:", soup.title.string)

    # Extract and print all the text content within the <p> tags
    paragraphs = soup.find_all('p')
    list_p.clear()  # Clear the list don't clear if you want to add older description
    error_message = "An appropriate representation of the requested resource could not be found on this server. This error was generated by Mod_Security."
    for p in paragraphs:
        cleaned_text = p.text.strip()
        if not cleaned_text or cleaned_text.isspace():
            continue
        if error_message in cleaned_text or cleaned_text == "":
            return 0
        pattern = r'[\t]{2,}|@'
        match = re.search(pattern, cleaned_text)
        if match:
            continue
        else:
            list_p.append(cleaned_text)
            print(cleaned_text)

    # Extract and print the URLs of all the images within the <img> tags
    if not os.path.exists('images'):
        os.makedirs('images')
    temple_dir = os.path.join('images', temple_name)
    if not os.path.exists(temple_dir):
        os.makedirs(temple_dir)

    # getting all image src
    images = soup.find_all('img')

    # Find all the links on the page
    ref_links = soup.find_all('a')

    # Process each link
    for link in ref_links:
        href = link.get('href')

        # Check if the link is not None
        if href is not None:
            # Construct the absolute URL
            if href.startswith('https://'):
                if href not in my_list:
                    my_list.append(href)
                    crawl(href, limit - 1, li, deity_name,
                          address, temple_name)
                    if flag % 6 == 0:
                        print("Reference Links:", href)
                    flag = flag + 1

    # Declaring Variables
    phone_official_site = "Phone number not available ,International phone number not available"
    location = address
    longitude = 0.0
    latitude = 0.0
    opening_hours = "Not Found Timing"
    email_official_site = "Email not available"

    # Scraped Description
    description = "\n".join(list_p)

    # Scraped Images Url from a tuple of path and size
    image_sizes = process_images(images, base_url, temple_name)
    image_sizes.sort(key=lambda x: x[1], reverse=True)  # Sort image sizes based on the second element
    list_img = [path for path, size in image_sizes]  # Separate the Path
    image_path = ""
    if len(list_img) > 1:
        image_path = list_img[1]
    # converting into string
    list_img_str = ', '.join(list_img)

    # Scraping Phone Number
    # Designed to only store the first number
    phone_number = re.search(r'\+\d{2}-\d{2}-\d{4}-\d{4}|\b\d{11}\b|\b9\d{9}\b|\+91-\d{10}', soup.text)
    if phone_number:
        phone_official_site = phone_number.group()
        phone_official_site = format_phone_number(phone_official_site)

    email_tags = soup.find_all('a', href=True)
    scrap_email = ' '.join(
        [re.sub(r'^mailto:', '', unquote(tag['href'])).strip() for tag in email_tags if 'mailto:' in tag['href']])
    if re.search(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', scrap_email):
        email_official_site = scrap_email

    # Scraping Address
    address_h3 = soup.find('h3', string='Contact Details')
    if address_h3:
        address_paragraph = address_h3.find_next('p')
        if address_paragraph:
            address = address_paragraph.get_text(separator='\n')
            location = address
        # else:
        #     print("Address details not found")
    # else:
    #     print("Address header not found")

    # To be updated
    ways_to_book = 'To Be Implemented'
    websites = li

    # Insert Data in Database
    insert_temple_data(temple_name, deity_name, description, image_path, location, latitude, longitude, opening_hours,
                       ways_to_book, websites, phone_official_site, email_official_site)
    # Inserting in Database from list_img
    for img_path in list_img:
        insert_temple_images(temple_name, img_path)
    return 1


def get_temple_details_by_api(temple_name):
    # fetching address from the temples tables
    fetch_address = fetch_temple_address(temple_name)
    address = fetch_address.split()[0] if fetch_address else None
    locationResults = get_location_details(temple_name + ' ' + address)
    location = locationResults['formatted_address'] if locationResults and locationResults[
        'formatted_address'] else "Empty address"
    latitude = locationResults['latitude'] if locationResults and locationResults['latitude'] else "Empty Latitude"
    longitude = locationResults['longitude'] if locationResults and locationResults['longitude'] else "Empty Longitude"
    opening_hours = locationResults['opening_hours'] if locationResults and locationResults[
        'opening_hours'] else "Empty Hours"
    phone_official_site = locationResults['phone_number'] if locationResults and locationResults[
        'phone_number'] else "Empty Phone"
    phone_official_site = format_phone_number(phone_official_site)
    email_official_site = locationResults['email'] if locationResults and locationResults['email'] else "Empty Email"
    # insert into table
    insert_temple_data_by_api(temple_name, location, latitude, longitude, opening_hours, phone_official_site,
                              email_official_site, )


# getting google search results link
def get_google_search_links(query):
    url = f"https://www.google.com/search?q={query}"
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'}

    response = requests.get(url, headers=headers)

    if response.status_code == 200:
        soup = BeautifulSoup(response.text, 'html.parser')
        # Adjust the class based on the current structure
        result_divs = soup.find_all('div', class_='tF2Cxc')

        links = []
        for result_div in result_divs:
            link_tag = result_div.find('a')
            if link_tag:
                href_value = link_tag.get('href')
                clean_url = href_value.split('&')[0]
                links.append(clean_url)

        return links
    else:
        print(f"Error: Failed to fetch {url}. Status code: {response.status_code}")
        return []


# Start the crawler by providing a seed URL
# q = input("Enter Topic name: ")
# deity = input("Enter Deity name: ")
# address = input("Enter Address: ")
q = "SRI VARADARAJA PERUMAL TEMPLE"
deity = "Shiva"
address = "KANCHIPURAM"
links = get_google_search_links(q)
crawlable_links_count = 0
index = 0
# link = "https://shirdi.tourismindia.co.in/sai-baba-samadhi-mandir-shirdi"
# crawl(link, 1, link, deity, address, q)
while crawlable_links_count < 3 and index < len(links):
    link = links[index]
    if skip_site in link or link.startswith("ppp"):
        index += 1
        continue
    else:
        result_web = link
        if result_web not in my_list_web:
            my_list_web.append(result_web)
            print("\nWebsite Url: ", link, "\n")
            if is_crawling_allowed(link):
                increment = crawl(link, 1, link, deity, address, q)
                crawlable_links_count += increment
            else:
                print(f"Warning: Crawling not allowed for {link} skipping this link")
    index += 1
# API Call and Update
get_temple_details_by_api(q)
